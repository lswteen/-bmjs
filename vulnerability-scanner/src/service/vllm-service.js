import { config } from '../core/config.js';

/**
 * vLLM API 호출 유틸리티
 * @param {string} prompt - 사용자 프롬프트
 * @param {object} options - 추가 옵션
 * @returns {Promise<string>} - AI 응답 텍스트
 */
export async function callVLLM(prompt, options = {}) {
    const {
        baseURL = config.vllmApiUrl,
        model = config.vllmModel,
        temperature = 0.7,
        maxTokens = 500,
        systemPrompt = 'You are a helpful assistant.'
    } = options;

    try {
        const response = await fetch(`${baseURL}/chat/completions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                model: model,
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: prompt }
                ],
                temperature: temperature,
                max_tokens: maxTokens,
                response_format: { type: 'json_object' } // JSON 응답 강제
            })
        });

        if (!response.ok) {
            throw new Error(`vLLM API Error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();

        // 응답에서 텍스트 추출
        const content = data.choices?.[0]?.message?.content;

        if (!content) {
            throw new Error('No content in vLLM response');
        }

        // JSON 응답인 경우 파싱하여 반환
        try {
            return JSON.parse(content);
        } catch {
            // JSON이 아니면 그대로 반환
            return content;
        }

    } catch (error) {
        console.error('❌ vLLM API 호출 실패:', error.message);
        throw error;
    }
}

/**
 * 사용 예시
 */
async function example() {
    try {
        // 예시 1: CVE 분석 요청
        const result = await callVLLM(
            'Analyze this CVE: CVE-2024-1234. Return JSON with severity, impact, and recommendation.',
            {
                baseURL: 'http://vllm-gpt-oss-120b/v1',
                systemPrompt: 'You are a cybersecurity expert. Always respond in valid JSON format.'
            }
        );

        console.log('✅ vLLM 응답:', result);

        // 예시 2: 코드 분석
        const codeAnalysis = await callVLLM(
            'Review this Java code for vulnerabilities: public class Test { ... }',
            {
                maxTokens: 1000
            }
        );

        console.log('✅ 코드 분석:', codeAnalysis);

    } catch (error) {
        console.error('호출 실패:', error);
    }
}

// 테스트 실행
// example();
